{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-351b1b18e785>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-351b1b18e785>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    python AgeGender.py --input sample1.jpg\u001b[0m\n\u001b[1;37m                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.2.0.34-cp37-cp37m-win_amd64.whl (33.0 MB)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\toshi\\anaconda3\\envs\\opencv_env\\lib\\site-packages (from opencv-python) (1.18.4)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.2.0.34\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-d9b30178a6ae>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-6-d9b30178a6ae>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    python AgeGender.py --input sample1.jpg\u001b[0m\n\u001b[1;37m                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#Using sample image \n",
    "python AgeGender.py --input sample1.jpg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-7-24e530f3bab3>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-7-24e530f3bab3>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    2\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def getFaceBox(net, frame, conf_threshold=0.7):\n",
    "\n",
    "    frameOpencvDnn = frame.copy()\n",
    "\n",
    "    frameHeight = frameOpencvDnn.shape[0]\n",
    "\n",
    "    frameWidth = frameOpencvDnn.shape[1]\n",
    "\n",
    "    blob = cv.dnn.blobFromImage(frameOpencvDnn, 1.0, (300, 300), [104, 117, 123], True, False)\n",
    "\n",
    " \n",
    "\n",
    "    net.setInput(blob)\n",
    "\n",
    "    detections = net.forward()\n",
    "\n",
    "    bboxes = []\n",
    "\n",
    "    for i in range(detections.shape[2]):\n",
    "\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "\n",
    "        if confidence > conf_threshold:\n",
    "\n",
    "            x1 = int(detections[0, 0, i, 3] * frameWidth)\n",
    "\n",
    "            y1 = int(detections[0, 0, i, 4] * frameHeight)\n",
    "\n",
    "            x2 = int(detections[0, 0, i, 5] * frameWidth)\n",
    "\n",
    "            y2 = int(detections[0, 0, i, 6] * frameHeight)\n",
    "\n",
    "            bboxes.append([x1, y1, x2, y2])\n",
    "\n",
    "            cv.rectangle(frameOpencvDnn, (x1, y1), (x2, y2), (0, 255, 0), int(round(frameHeight/150)), 8)\n",
    "    return frameOpencvDnn, bboxes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "genderProto = \"gender_deploy.prototxt\"\n",
    "\n",
    "genderModel = \"gender_net.caffemodel\"\n",
    "\n",
    "ageNet = cv.dnn.readNet(ageModel, ageProto)\n",
    "\n",
    " \n",
    "\n",
    "genderList = ['Male', 'Female']\n",
    "\n",
    " \n",
    "\n",
    "blob = cv.dnn.blobFromImage(face, 1, (227, 227), MODEL_MEAN_VALUES, swapRB=False)\n",
    "\n",
    "genderNet.setInput(blob)\n",
    "\n",
    "genderPreds = genderNet.forward()\n",
    "\n",
    "gender = genderList[genderPreds[0].argmax()]\n",
    "\n",
    "print(\"Gender Output : {}\".format(genderPreds))\n",
    "\n",
    "print(\"Gender : {}\".format(gender))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ageProto = \"age_deploy.prototxt\"\n",
    "\n",
    "ageModel = \"age_net.caffemodel\"\n",
    "\n",
    "ageNet = cv.dnn.readNet(ageModel, ageProto)\n",
    "\n",
    " \n",
    "\n",
    "ageList = ['(0 - 2)', '(4 - 6)', '(8 - 12)', '(15 - 20)', '(25 - 32)', '(38 - 43)', '(48 - 53)', '(60 - 100)']\n",
    "\n",
    " \n",
    "\n",
    "ageNet.setInput(blob)\n",
    "\n",
    "agePreds = ageNet.forward()\n",
    "\n",
    "age = ageList[agePreds[0].argmax()]\n",
    "\n",
    "print(\"Gender Output : {}\".format(agePreds))\n",
    "\n",
    "print(\"Gender : {}\".format(age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"{}, {}\".format(gender, age)\n",
    "\n",
    "cv.putText(frameFace, label, (bbox[0], bbox[1]-20), cv.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 3, cv.LINE_AA)\n",
    "\n",
    "cv.imshow(\"Age Gender Demo\", frameFace)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
